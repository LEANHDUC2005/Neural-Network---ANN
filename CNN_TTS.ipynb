{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8EuKP2qW3Pn9NbdO5DZCL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEANHDUC2005/Neural-Network---ANN/blob/main/CNN_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1wgN3vZxVvp",
        "outputId": "5403d8f7-a8bc-492f-e5b7-3a6a3cd29970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải LJSpeech-1.1...\n",
            "Tải xong.\n",
            "Đang giải nén dữ liệu...\n",
            "Giải nén xong.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# Đường dẫn lưu dữ liệu\n",
        "data_dir = \"/content/drive/MyDrive/TTS_Project/data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# URL của bộ dữ liệu LJSpeech-1.1\n",
        "url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
        "filename = os.path.join(data_dir, \"LJSpeech-1.1.tar.bz2\")\n",
        "\n",
        "# Tải dữ liệu nếu chưa có\n",
        "if not os.path.exists(filename):\n",
        "    print(\"Đang tải LJSpeech-1.1...\")\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    print(\"Tải xong.\")\n",
        "\n",
        "# Giải nén dữ liệu\n",
        "extract_path = os.path.join(data_dir, \"LJSpeech-1.1\")\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Đang giải nén dữ liệu...\")\n",
        "    with tarfile.open(filename, \"r:bz2\") as tar:\n",
        "        tar.extractall(path=data_dir)\n",
        "    print(\"Giải nén xong.\")\n",
        "else:\n",
        "    print(\"Dữ liệu đã được giải nén.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Đường dẫn đến file metadata\n",
        "metadata_path = os.path.join(extract_path, \"metadata.csv\")\n",
        "\n",
        "# Đọc metadata\n",
        "metadata = pd.read_csv(metadata_path, sep=\"|\", header=None, names=[\"id\", \"text\", \"normalized_text\"])\n",
        "\n",
        "# Thêm cột đường dẫn đến file âm thanh\n",
        "metadata[\"audio_path\"] = metadata[\"id\"].apply(lambda x: os.path.join(extract_path, \"wavs\", f\"{x}.wav\"))\n",
        "\n",
        "# Hiển thị 5 dòng đầu tiên\n",
        "metadata.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8njIMepn1YGb",
        "outputId": "ba6fa17c-68b1-4dce-8d2e-2772004eab2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                               text  \\\n",
              "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
              "1  LJ001-0002                     in being comparatively modern.   \n",
              "2  LJ001-0003  For although the Chinese took impressions from...   \n",
              "3  LJ001-0004  produced the block books, which were the immed...   \n",
              "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
              "\n",
              "                                     normalized_text  \\\n",
              "0  Printing, in the only sense with which we are ...   \n",
              "1                     in being comparatively modern.   \n",
              "2  For although the Chinese took impressions from...   \n",
              "3  produced the block books, which were the immed...   \n",
              "4  the invention of movable metal letters in the ...   \n",
              "\n",
              "                                          audio_path  \n",
              "0  /content/drive/MyDrive/TTS_Project/data/LJSpee...  \n",
              "1  /content/drive/MyDrive/TTS_Project/data/LJSpee...  \n",
              "2  /content/drive/MyDrive/TTS_Project/data/LJSpee...  \n",
              "3  /content/drive/MyDrive/TTS_Project/data/LJSpee...  \n",
              "4  /content/drive/MyDrive/TTS_Project/data/LJSpee...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66bda17c-3c75-4af2-bea0-e84ee1224699\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>audio_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LJ001-0001</td>\n",
              "      <td>Printing, in the only sense with which we are ...</td>\n",
              "      <td>Printing, in the only sense with which we are ...</td>\n",
              "      <td>/content/drive/MyDrive/TTS_Project/data/LJSpee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LJ001-0002</td>\n",
              "      <td>in being comparatively modern.</td>\n",
              "      <td>in being comparatively modern.</td>\n",
              "      <td>/content/drive/MyDrive/TTS_Project/data/LJSpee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LJ001-0003</td>\n",
              "      <td>For although the Chinese took impressions from...</td>\n",
              "      <td>For although the Chinese took impressions from...</td>\n",
              "      <td>/content/drive/MyDrive/TTS_Project/data/LJSpee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LJ001-0004</td>\n",
              "      <td>produced the block books, which were the immed...</td>\n",
              "      <td>produced the block books, which were the immed...</td>\n",
              "      <td>/content/drive/MyDrive/TTS_Project/data/LJSpee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LJ001-0005</td>\n",
              "      <td>the invention of movable metal letters in the ...</td>\n",
              "      <td>the invention of movable metal letters in the ...</td>\n",
              "      <td>/content/drive/MyDrive/TTS_Project/data/LJSpee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66bda17c-3c75-4af2-bea0-e84ee1224699')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66bda17c-3c75-4af2-bea0-e84ee1224699 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66bda17c-3c75-4af2-bea0-e84ee1224699');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8199000b-c5f2-40cb-871b-ec272119e859\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8199000b-c5f2-40cb-871b-ec272119e859')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8199000b-c5f2-40cb-871b-ec272119e859 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata",
              "summary": "{\n  \"name\": \"metadata\",\n  \"rows\": 13100,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13100,\n        \"samples\": [\n          \"LJ015-0247\",\n          \"LJ028-0475\",\n          \"LJ013-0049\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13074,\n        \"samples\": [\n          \"He acknowledged the encounter with the police officer on the second floor.\",\n          \"Oswald's behavior after the assassination throws little light on his motives.\",\n          \"The Commission also regards the security arrangements worked out by Lawson and Sorrels at Love Field as entirely adequate.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13058,\n        \"samples\": [\n          \"in the sale of unsound mortgages and in many other ways in which the public lost billions of dollars.\",\n          \"both adaptations to an aerial environment;\",\n          \"I will quote an extract from the reverend gentleman's own journal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13100,\n        \"samples\": [\n          \"/content/drive/MyDrive/TTS_Project/data/LJSpeech-1.1/wavs/LJ015-0247.wav\",\n          \"/content/drive/MyDrive/TTS_Project/data/LJSpeech-1.1/wavs/LJ028-0475.wav\",\n          \"/content/drive/MyDrive/TTS_Project/data/LJSpeech-1.1/wavs/LJ013-0049.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    # Convert to string to handle potential float values\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z.,!?'\\s]\", \"\", text)  # Chỉ giữ lại ký tự a-z và một số dấu cơ bản\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Bỏ khoảng trắng thừa\n",
        "    return text\n",
        "\n",
        "metadata[\"normalized_text\"] = metadata[\"normalized_text\"].apply(normalize_text)\n",
        "metadata.head()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Chia tập train + val trước\n",
        "train_val, test = train_test_split(metadata, test_size=0.2, random_state=42)\n",
        "train, val = train_test_split(train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
        "\n",
        "print(f\"Số lượng mẫu:\")\n",
        "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
        "output_dir = os.path.join(data_dir, \"splits\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "train.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
        "val.to_csv(os.path.join(output_dir, \"val.csv\"), index=False)\n",
        "test.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)\n",
        "\n",
        "# ---The fix---\n",
        "# Recreate train_files and val_files from your DataFrames to ensure that they reference the DataFrames\n",
        "train_files = list(zip(train[\"audio_path\"], train[\"normalized_text\"])) # Create list of (audio_path, text) tuples for training\n",
        "val_files = list(zip(val[\"audio_path\"], val[\"normalized_text\"]))   # Create list of (audio_path, text) tuples for validation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXkvX5141bPJ",
        "outputId": "f47e29d1-dc10-4165-f179-2ef47988d5c1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng mẫu:\n",
            "Train: 7860, Val: 2620, Test: 2620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNNTTS(nn.Module):\n",
        "    def __init__(self, vocab_size=70, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(embed_dim, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Conv1d(256, 512, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Decoder (simple upsample + conv transpose)\n",
        "        # Adjust padding to match output shape\n",
        "        # Changed stride to 1 and added padding\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose1d(512, 80, kernel_size=5, stride=2, padding=2),\n",
        "            nn.Tanh()  # Add a Tanh activation to restrict output range\n",
        "        )\n",
        "\n",
        "        # PostNet (refine mel)\n",
        "        self.postnet = nn.Sequential(\n",
        "            nn.Conv1d(80, 512, kernel_size=5, padding=2),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv1d(512, 80, kernel_size=5, padding=2),\n",
        "            )\n",
        "    def forward(self, x, target_len=None):  # Add target_len argument\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.encoder(x)\n",
        "        mel = self.decoder(x)\n",
        "\n",
        "        # Calculate padding to match target length ONLY IF target_len is provided\n",
        "        if target_len is not None: # Use target_len if provided\n",
        "            max_mel_len = target_len\n",
        "            padding_size = max_mel_len - mel.shape[2]\n",
        "\n",
        "            # Apply padding if necessary\n",
        "            if padding_size > 0:\n",
        "                padding = torch.zeros(mel.shape[0], mel.shape[1], padding_size, device=mel.device)  # Zeros padding\n",
        "                mel = torch.cat([mel, padding], dim=2)\n",
        "            elif padding_size < 0:\n",
        "                mel = mel[:, :, :max_mel_len]  # Truncate if output is longer\n",
        "        # Otherwise, NO padding adjustment is performed\n",
        "\n",
        "        mel_post = mel + self.postnet(mel)\n",
        "        return mel_post\n",
        "\n",
        "\n",
        "import string\n",
        "\n",
        "# Tạo bảng chữ cái\n",
        "vocab = list(\" \" + string.ascii_lowercase + \".,!?'-\")  # 1 space + 26 chữ cái + 6 dấu\n",
        "char2id = {ch: i+1 for i, ch in enumerate(vocab)}  # Start from 1\n",
        "char2id[\"<pad>\"] = 0\n",
        "id2char = {i: ch for ch, i in char2id.items()}\n",
        "\n",
        "def text_to_sequence(text, char2id, max_len=200):\n",
        "    ids = [char2id.get(ch, 0) for ch in text]  # default to <pad> if unknown\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))  # pad\n",
        "    return torch.tensor(ids[:max_len])\n",
        "\n"
      ],
      "metadata": {
        "id": "fyzrqgKR2z_v"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7EXQ3FBd4MHV",
        "outputId": "e8338739-7652-414d-f49c-e154f40515e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "!pip install torchaudio # install torchaudio\n",
        "import torchaudio\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_mel_spectrogram(wav_path, save_path):\n",
        "    \"\"\"\n",
        "    Extracts mel spectrogram from a WAV file and saves it as an NPY file.\n",
        "\n",
        "    Args:\n",
        "        wav_path: Path to the WAV file.\n",
        "        save_path: Path to save the mel spectrogram as an NPY file.\n",
        "    \"\"\"\n",
        "    waveform, sample_rate = torchaudio.load(wav_path) # load waveform using torchaudio\n",
        "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_mels=80 # Adjust n_mels as needed\n",
        "    )(waveform).squeeze(0).numpy()\n",
        "\n",
        "    # Apply min-max normalization\n",
        "    min_val = mel_spectrogram.min()\n",
        "    max_val = mel_spectrogram.max()\n",
        "    normalized_mel_spectrogram = (mel_spectrogram - min_val) / (max_val - min_val)\n",
        "\n",
        "    np.save(save_path, normalized_mel_spectrogram)\n",
        "\n",
        "# Update your dataset class to perform the same normalization for target Mel Spectrograms:\n",
        "class LJSpeechDataset(Dataset):\n",
        "    def __init__(self, files, char2id, max_text_len=200):\n",
        "        self.files = files\n",
        "        self.char2id = char2id\n",
        "        self.max_text_len = max_text_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wav_path, text = self.files[idx]\n",
        "        mel = np.load(wav_path.replace(\".wav\", \".npy\"))  # Giả định đã chuẩn hóa\n",
        "\n",
        "        # Apply min-max normalization if not already normalized\n",
        "        min_val = mel.min()\n",
        "        max_val = mel.max()\n",
        "        if (max_val - min_val) > 0: # avoid division by zero\n",
        "            mel = (mel - min_val) / (max_val - min_val)\n",
        "\n",
        "        mel_tensor = torch.tensor(mel, dtype=torch.float32)  # (80, T)\n",
        "        text_tensor = text_to_sequence(text.lower(), self.char2id, self.max_text_len)\n",
        "        return text_tensor, mel_tensor\n",
        "def collate_fn(batch):\n",
        "    texts, mels = zip(*batch)\n",
        "    max_text_len = max([t.size(0) for t in texts])\n",
        "    max_mel_len = max([m.size(1) for m in mels])\n",
        "\n",
        "    texts_padded = torch.stack([F.pad(t, (0, max_text_len - t.size(0))) for t in texts])\n",
        "\n",
        "    # Pad mels to the maximum length\n",
        "    mels_padded = torch.zeros(len(mels), mels[0].shape[0], max_mel_len) # Create a zero tensor with the desired shape\n",
        "    for i, mel in enumerate(mels):\n",
        "        mels_padded[i, :, :mel.shape[1]] = mel # Copy the mel spectrogram into the padded tensor\n",
        "\n",
        "\n",
        "    return texts_padded, mels_padded\n",
        "\n",
        "# Create train_files and val_files from your DataFrames\n",
        "\n",
        "train_dataset = LJSpeechDataset(train_files, char2id)\n",
        "val_dataset = LJSpeechDataset(val_files, char2id)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "model = CNNTTS(vocab_size=len(char2id)).cuda()\n",
        "criterion = MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "\n",
        "            #Get target_len from y\n",
        "            target_len = y.shape[2]\n",
        "\n",
        "            #Pass target_len to model.forward\n",
        "            y_pred = model(x, target_len=target_len)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def train(model, train_loader, val_loader, epochs):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "\n",
        "            # Get target_len from y for training as well\n",
        "            target_len = y.shape[2]\n",
        "\n",
        "            # Pass target_len to model.forward during training\n",
        "            y_pred = model(x, target_len=target_len)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss = evaluate(model, val_loader)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "        # Inside the training loop\n",
        "        # After every training loss evaluation.\n",
        "\n",
        "        scheduler.step(train_loss)  # Using training loss for scheduling\n",
        "\n",
        "train(model, train_loader, val_loader, epochs=50)\n",
        "\n",
        "torch.save(model.state_dict(), \"cnntts_model.pth\")\n",
        "print(\"Mô hình đã được lưu vào: cnntts_model.pth\")\n",
        "\n",
        "model = CNNTTS(vocab_size=len(char2id)).cuda()\n",
        "model.load_state_dict(torch.load(\"cnntts_model.pth\"))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d52V2tKX3GvN",
        "outputId": "aeb14309-08ce-4805-fcee-207a5790235d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n",
            "Epoch 1 | Train Loss: 0.0017 | Val Loss: 0.0006\n",
            "Epoch 2 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
            "Epoch 3 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
            "Epoch 4 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
            "Epoch 5 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 6 | Train Loss: 0.0283 | Val Loss: 0.0006\n",
            "Epoch 7 | Train Loss: 0.0013 | Val Loss: 0.0010\n",
            "Epoch 8 | Train Loss: 0.0024 | Val Loss: 0.0014\n",
            "Epoch 9 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
            "Epoch 10 | Train Loss: 0.0006 | Val Loss: 0.0008\n",
            "Epoch 11 | Train Loss: 0.0009 | Val Loss: 0.0012\n",
            "Epoch 12 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
            "Epoch 13 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
            "Epoch 14 | Train Loss: 0.0005 | Val Loss: 0.0004\n",
            "Epoch 15 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 16 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
            "Epoch 17 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
            "Epoch 18 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 19 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 20 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 21 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 22 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 23 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 24 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 25 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 26 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 27 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 28 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 29 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 30 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 31 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 32 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 33 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 34 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 35 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 36 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 37 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 38 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 39 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 40 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 41 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 42 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 43 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 44 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 45 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 46 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 47 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 48 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 49 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Epoch 50 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
            "Mô hình đã được lưu vào: cnntts_model.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNTTS(\n",
              "  (embedding): Embedding(34, 128)\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): ConvTranspose1d(512, 80, kernel_size=(5,), stride=(2,), padding=(2,))\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (postnet): Sequential(\n",
              "    (0): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "    (1): Tanh()\n",
              "    (2): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbkZtnQNSodN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}