{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEANHDUC2005/Neural-Network---ANN/blob/main/B%E1%BA%A3n_sao_c%E1%BB%A7a_Fastspeech2_Hifigan_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gSSrWvChp8-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16883ac9-37fe-48d1-c32f-745d038f81d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting phonemizer\n",
            "  Downloading phonemizer-3.3.0-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from phonemizer) (1.4.2)\n",
            "Collecting segments (from phonemizer)\n",
            "  Downloading segments-2.3.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.11/dist-packages (from phonemizer) (25.3.0)\n",
            "Collecting dlinfo (from phonemizer)\n",
            "  Downloading dlinfo-2.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from phonemizer) (4.13.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from segments->phonemizer) (2024.11.6)\n",
            "Collecting csvw>=1.5.6 (from segments->phonemizer)\n",
            "  Downloading csvw-3.5.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Collecting isodate (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\n",
            "Collecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\n",
            "Collecting language-tags (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading language_tags-1.2.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting rdflib (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting colorama (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.3)\n",
            "Downloading phonemizer-3.3.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dlinfo-2.0.0-py3-none-any.whl (3.7 kB)\n",
            "Downloading segments-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading csvw-3.5.1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rfc3986, language-tags, unidecode, rdflib, isodate, dlinfo, colorama, csvw, segments, phonemizer\n",
            "Successfully installed colorama-0.4.6 csvw-3.5.1 dlinfo-2.0.0 isodate-0.7.2 language-tags-1.2.0 phonemizer-3.3.0 rdflib-7.1.4 rfc3986-1.5.0 segments-2.3.0 unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# FastSpeech 2 + HiFi-GAN: Training from scratch (LJSpeech)\n",
        "# Compatible with Google Colab Free Tier (T4 GPU)\n",
        "\n",
        "# Step 1: Install dependencies\n",
        "!pip install torch torchaudio numpy matplotlib scipy tensorboard\n",
        "!pip install phonemizer unidecode librosa\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y espeak-ng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_zYonhAwpzO",
        "outputId": "d29a61ab-9aad-41c3-e19c-a509513c40de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 4,526 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\n",
            "Fetched 4,526 kB in 2s (2,700 kB/s)\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install montreal-forced-aligner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q70Lb3d4hAiM",
        "outputId": "de5bab5c-4091-4f24-8818-c2aa268b52db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting montreal-forced-aligner\n",
            "  Downloading montreal_forced_aligner-3.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting biopython (from montreal-forced-aligner)\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (8.1.8)\n",
            "Collecting dataclassy (from montreal-forced-aligner)\n",
            "  Downloading dataclassy-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting kneed (from montreal-forced-aligner)\n",
            "  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (2.0.2)\n",
            "Collecting praatio>=6.0.0 (from montreal-forced-aligner)\n",
            "  Downloading praatio-6.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (13.9.4)\n",
            "Collecting rich-click (from montreal-forced-aligner)\n",
            "  Downloading rich_click-1.8.8-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (0.13.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4 in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from montreal-forced-aligner) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from praatio>=6.0.0->montreal-forced-aligner) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4->montreal-forced-aligner) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from kneed->montreal-forced-aligner) (1.15.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->montreal-forced-aligner) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->montreal-forced-aligner) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->montreal-forced-aligner) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->montreal-forced-aligner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->montreal-forced-aligner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->montreal-forced-aligner) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->montreal-forced-aligner) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->montreal-forced-aligner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->montreal-forced-aligner) (2.19.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->montreal-forced-aligner) (2.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->montreal-forced-aligner) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->montreal-forced-aligner) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->montreal-forced-aligner) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->montreal-forced-aligner) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->montreal-forced-aligner) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->montreal-forced-aligner) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->montreal-forced-aligner) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->montreal-forced-aligner) (2.22)\n",
            "Downloading montreal_forced_aligner-3.2.2-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.6/406.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading praatio-6.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.0/80.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclassy-1.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n",
            "Downloading rich_click-1.8.8-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: praatio, dataclassy, biopython, kneed, rich-click, montreal-forced-aligner\n",
            "Successfully installed biopython-1.85 dataclassy-1.0.1 kneed-0.8.5 montreal-forced-aligner-3.2.2 praatio-6.2.0 rich-click-1.8.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mfa model download acoustic english\n",
        "!mfa model download dictionary english\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMi_guoChEyj",
        "outputId": "6364cccb-7230-4261-c2c8-1ebc60b51bb5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mfa\", line 5, in <module>\n",
            "    from montreal_forced_aligner.command_line.mfa import mfa_cli\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/montreal_forced_aligner/__init__.py\", line 4, in <module>\n",
            "    import montreal_forced_aligner.acoustic_modeling as acoustic_modeling\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/montreal_forced_aligner/acoustic_modeling/__init__.py\", line 7, in <module>\n",
            "    from montreal_forced_aligner.acoustic_modeling.base import AcousticModelTrainingMixin  # noqa\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/montreal_forced_aligner/acoustic_modeling/base.py\", line 11, in <module>\n",
            "    from _kalpy.gmm import AccumAmDiagGmm\n",
            "ModuleNotFoundError: No module named '_kalpy'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mfa\", line 5, in <module>\n",
            "    from montreal_forced_aligner.command_line.mfa import mfa_cli\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/montreal_forced_aligner/__init__.py\", line 4, in <module>\n",
            "    import montreal_forced_aligner.acoustic_modeling as acoustic_modeling\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/montreal_forced_aligner/acoustic_modeling/__init__.py\", line 7, in <module>\n",
            "    from montreal_forced_aligner.acoustic_modeling.base import AcousticModelTrainingMixin  # noqa\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/montreal_forced_aligner/acoustic_modeling/base.py\", line 11, in <module>\n",
            "    from _kalpy.gmm import AccumAmDiagGmm\n",
            "ModuleNotFoundError: No module named '_kalpy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clone HiFi-GAN for waveform decoder\n",
        "!git clone https://github.com/jik876/hifi-gan.git\n",
        "%cd hifi-gan\n",
        "!pip install -r requirements.txt\n",
        "%cd .."
      ],
      "metadata": {
        "id": "_q3PKDUCqBbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a530b0-88f1-4479-fd15-b1f552a33ade"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hifi-gan'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48 (from 1)\u001b[K\n",
            "Receiving objects: 100% (48/48), 620.94 KiB | 2.02 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "/content/hifi-gan\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.4.0\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Download and extract LJSpeech dataset\n",
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar -xjf LJSpeech-1.1.tar.bz2"
      ],
      "metadata": {
        "id": "t54L6RkmqIht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340769cb-5dd2-46b9-ef11-45cf3fe43571"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-07 01:47:39--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 143.244.50.89, 2400:52e0:1a01::985:1\n",
            "Connecting to data.keithito.com (data.keithito.com)|143.244.50.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [text/plain]\n",
            "Saving to: ‘LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "LJSpeech-1.1.tar.bz 100%[===================>]   2.56G   215MB/s    in 14s     \n",
            "\n",
            "2025-05-07 01:47:53 (190 MB/s) - ‘LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define FastSpeech 2 components\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=1000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)].to(x.device)\n",
        "\n",
        "class VariancePredictor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, input_dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, input_dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.conv1(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return self.linear(x).squeeze(-1)\n",
        "\n",
        "def length_regulator(x, durations):\n",
        "    output = []\n",
        "    for i in range(x.size(0)):\n",
        "        expanded = [x[i, j].repeat(int(max(durations[i][j], 1)), 1) for j in range(x.size(1))]\n",
        "        output.append(torch.cat(expanded, dim=0))\n",
        "    max_len = max([o.size(0) for o in output])\n",
        "    output_padded = torch.stack([\n",
        "        F.pad(o, (0, 0, 0, max_len - o.size(0))) for o in output\n",
        "    ])\n",
        "    return output_padded\n",
        "\n",
        "class VarianceAdaptor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.duration_predictor = VariancePredictor(input_dim)\n",
        "        self.pitch_predictor = VariancePredictor(input_dim)\n",
        "        self.energy_predictor = VariancePredictor(input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        duration = self.duration_predictor(x)\n",
        "        pitch = self.pitch_predictor(x)\n",
        "        energy = self.energy_predictor(x)\n",
        "\n",
        "        durations_rounded = torch.clamp(duration * 5, min=1).round().long()  # Boost duration prediction\n",
        "        x = length_regulator(x, durations_rounded)\n",
        "\n",
        "        return x, duration, pitch, energy\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x.transpose(1, 2)).transpose(1, 2)\n",
        "        x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, mel_dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.linear = nn.Linear(hidden_dim, mel_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x.transpose(1, 2)).transpose(1, 2)\n",
        "        x = self.norm(x)\n",
        "        return self.linear(x)\n",
        "\n",
        "class FastSpeech2(nn.Module):\n",
        "    def __init__(self, vocab_size=300, d_model=256, mel_dim=80):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.encoder = Encoder(d_model, d_model)\n",
        "        self.variance_adaptor = VarianceAdaptor(d_model)\n",
        "        self.decoder = Decoder(d_model, mel_dim)\n",
        "\n",
        "    def forward(self, phoneme_ids):\n",
        "        x = self.embedding(phoneme_ids)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.encoder(x)\n",
        "        x, dur, pitch, energy = self.variance_adaptor(x)\n",
        "        mel = self.decoder(x)\n",
        "        return mel, dur, pitch, energy\n",
        "\n",
        "class FastSpeech2(nn.Module):\n",
        "    def __init__(self, vocab_size=300, d_model=256, mel_dim=80):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.encoder = Encoder(d_model, d_model)\n",
        "        self.variance_adaptor = VarianceAdaptor(d_model)\n",
        "        self.decoder = Decoder(d_model, mel_dim)\n",
        "\n",
        "    def forward(self, phoneme_ids):\n",
        "        x = self.embedding(phoneme_ids)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.encoder(x)\n",
        "        x, dur, pitch, energy = self.variance_adaptor(x)\n",
        "        mel = self.decoder(x)\n",
        "        return mel, dur, pitch, energy"
      ],
      "metadata": {
        "id": "ZBnjIlOWqLN-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "qXmbITNBettQ",
        "outputId": "6c327391-03ee-448b-c083-9d376bf6bfb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-da0a4cb5d92d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"mel_pred.shape: {mel.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade phonemizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB5Hp-jZxNMU",
        "outputId": "b48962a4-4c27-42e7-dffe-dbdbbaf5ee63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phonemizer in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from phonemizer) (1.4.2)\n",
            "Requirement already satisfied: segments in /usr/local/lib/python3.11/dist-packages (from phonemizer) (2.3.0)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.11/dist-packages (from phonemizer) (25.3.0)\n",
            "Requirement already satisfied: dlinfo in /usr/local/lib/python3.11/dist-packages (from phonemizer) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from phonemizer) (4.13.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from segments->phonemizer) (2024.11.6)\n",
            "Requirement already satisfied: csvw>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from segments->phonemizer) (3.5.1)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.7.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\n",
            "Requirement already satisfied: rfc3986<2 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.32.3)\n",
            "Requirement already satisfied: language-tags in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (7.1.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Preprocess LJSpeech to extract phonemes and mel-spectrograms\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from phonemizer import phonemize\n",
        "from phonemizer.separator import Separator\n",
        "from unidecode import unidecode\n",
        "from tqdm import tqdm\n",
        "import torchaudio\n",
        "from phonemizer.backend import EspeakBackend\n",
        "# Config\n",
        "LJ_PATH = \"LJSpeech-1.1\"\n",
        "SAMPLING_RATE = 22050\n",
        "N_MELS = 80\n",
        "HOP_LENGTH = 256\n",
        "\n",
        "# Phoneme conversion\n",
        "from phonemizer import phonemize\n",
        "backend = EspeakBackend(language='en-us', preserve_punctuation=True)\n",
        "def text_to_phonemes(text):\n",
        "    return backend.phonemize([text], strip=True)[0]\n",
        "    text = unidecode(text.strip())\n",
        "    phones = phonemize(text, language='en-us', backend='espeak', separator=Separator(phone=' ', syllable=''))\n",
        "    return phones\n",
        "\n",
        "# Create mel-spectrogram\n",
        "def wav_to_mel(wav_path):\n",
        "    y, sr = librosa.load(wav_path, sr=SAMPLING_RATE)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return mel_db.T  # [T, 80]\n",
        "\n",
        "# Prepare dataset (subset for quick demo)\n",
        "metadata_path = os.path.join(LJ_PATH, \"metadata.csv\")\n",
        "with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Pick a small subset for demo\n",
        "data = []\n",
        "for line in tqdm(lines[:100]):\n",
        "    parts = line.strip().split(\"|\")\n",
        "    wav_path = os.path.join(LJ_PATH, \"wavs\", parts[0] + \".wav\")\n",
        "    text = parts[2]\n",
        "    phones = text_to_phonemes(text)\n",
        "    mel = wav_to_mel(wav_path)\n",
        "    data.append((phones, mel))\n",
        "\n",
        "#Save to disk (optional):\n",
        "torch.save(data, \"train_subset.pt\")\n"
      ],
      "metadata": {
        "id": "3PcL8WmHqL67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e456058-67b7-4525-ff80-ff374b05a23d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "  1%|          | 1/100 [00:01<02:45,  1.67s/it]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 10%|█         | 10/100 [00:01<00:11,  7.58it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 19%|█▉        | 19/100 [00:01<00:05, 15.71it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 27%|██▋       | 27/100 [00:01<00:03, 23.66it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 36%|███▌      | 36/100 [00:02<00:01, 33.14it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 46%|████▌     | 46/100 [00:02<00:01, 44.45it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 56%|█████▌    | 56/100 [00:02<00:00, 55.02it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 300.0% of the lines (3/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 65%|██████▌   | 65/100 [00:02<00:00, 61.20it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 74%|███████▍  | 74/100 [00:02<00:00, 63.70it/s]WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 82%|████████▏ | 82/100 [00:02<00:00, 60.17it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            " 90%|█████████ | 90/100 [00:02<00:00, 55.75it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 200.0% of the lines (2/1)\n",
            " 97%|█████████▋| 97/100 [00:02<00:00, 56.25it/s]WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "WARNING:phonemizer:words count mismatch on 100.0% of the lines (1/1)\n",
            "100%|██████████| 100/100 [00:03<00:00, 32.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PDf5NLaS4yaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mv hifi_gan hifi-gan\n"
      ],
      "metadata": {
        "id": "C5jEwcz91Fwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v4-LJIIc5BR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Use pretrained HiFi-GAN (SpeechBrain) to synthesize .wav from mel\n",
        "!pip install speechbrain --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91yUlZzB5Bp-",
        "outputId": "11038b4c-c72a-4842-8a05-757c92c8f697"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/864.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/864.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/117.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/739.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import HIFIGAN\n",
        "\n",
        "hifi_model = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"pretrained-hifigan\")\n",
        "\n",
        "# Function to synthesize waveform from mel\n",
        "# Input shape: (n_mels=80, T)\n",
        "def mel_to_wav(mel):\n",
        "    with torch.no_grad():\n",
        "        if mel.dim() == 2:\n",
        "            mel = mel.unsqueeze(0)\n",
        "        wav = hifi_model.decode_batch(mel).squeeze().cpu().numpy()\n",
        "    return wav\n",
        "\n",
        "# Step 7: Check compatibility\n",
        "# Ensure FastSpeech 2 mel output is compatible with HiFi-GAN\n",
        "\n",
        "def check_mel_specs(mel):\n",
        "    assert mel.shape[1] > 0, \"Mel-spectrogram has no time steps\"\n",
        "    assert mel.shape[2] == 80, f\"Expected 80 mel channels, got {mel.shape[2]}\"\n",
        "    print(\"✔ Mel has 80 channels\")\n",
        "\n",
        "    sample_rate = 22050\n",
        "    hop_length = 256\n",
        "    print(f\"✔ Target sample_rate = {sample_rate}, hop_length = {hop_length}\")\n",
        "\n",
        "# Example test\n",
        "example_mel = torch.randn(1, 100, 80)  # [B, T, n_mels]\n",
        "check_mel_specs(example_mel)\n",
        "\n",
        "# Test synthesis\n",
        "waveform = mel_to_wav(example_mel[0].transpose(0, 1))\n",
        "print(f\"Generated waveform shape: {waveform.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw1WgrsB4t5E",
        "outputId": "83ad35e4-394d-4cb4-9708-4e0f261fff1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n",
            "<ipython-input-5-3f7f0f0a73bb>:2: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  from speechbrain.pretrained import HIFIGAN\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/pretrained-hifigan/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/tts-hifigan-ljspeech' if not cached\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in pretrained-hifigan.\n",
            "INFO:speechbrain.utils.fetching:Fetch generator.ckpt: Using symlink found at '/content/pretrained-hifigan/generator.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"generator\"] = /content/pretrained-hifigan/generator.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: generator\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): generator -> /content/pretrained-hifigan/generator.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Mel has 80 channels\n",
            "✔ Target sample_rate = 22050, hop_length = 256\n",
            "Generated waveform shape: (28160,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- Configuration ---\n",
        "LJ_PATH = \"LJSpeech-1.1\"\n",
        "SAMPLE_RATE = 22050\n",
        "N_MELS = 80\n",
        "HOP_LENGTH = 256\n",
        "\n",
        "# --- Feature extraction ---\n",
        "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=SAMPLE_RATE,\n",
        "    n_fft=1024,\n",
        "    win_length=1024,\n",
        "    hop_length=HOP_LENGTH,\n",
        "    n_mels=N_MELS\n",
        ")\n",
        "\n",
        "def wav_to_mel(wav_path):\n",
        "    wav, _ = librosa.load(wav_path, sr=SAMPLE_RATE)\n",
        "    wav_tensor = torch.tensor(wav).unsqueeze(0)\n",
        "    mel = mel_transform(wav_tensor).squeeze(0).transpose(0, 1)  # [T, n_mels]\n",
        "    return mel\n",
        "\n",
        "# --- Dummy phoneme tokenizer ---\n",
        "def text_to_dummy_phonemes(text):\n",
        "    return [ord(c) % 256 for c in text if c.isalnum()]\n",
        "\n",
        "# --- Dataset and Dataloader ---\n",
        "class LJSubset(Dataset):\n",
        "    def __init__(self, max_samples=100):\n",
        "        self.data = []\n",
        "        with open(os.path.join(LJ_PATH, \"metadata.csv\"), \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f.readlines()[:max_samples]:\n",
        "                parts = line.strip().split(\"|\")\n",
        "                wav_path = os.path.join(LJ_PATH, \"wavs\", parts[0] + \".wav\")\n",
        "                text = parts[2]\n",
        "                phoneme_ids = text_to_dummy_phonemes(text)\n",
        "                mel = wav_to_mel(wav_path)\n",
        "                self.data.append((phoneme_ids, mel))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        phones, mel = self.data[idx]\n",
        "        phones = torch.tensor(phones, dtype=torch.long)\n",
        "        return phones, mel\n",
        "\n",
        "def collate_fn(batch):\n",
        "    phones_batch, mel_batch = zip(*batch)\n",
        "    phones_padded = nn.utils.rnn.pad_sequence(phones_batch, batch_first=True, padding_value=0)\n",
        "    mel_padded = nn.utils.rnn.pad_sequence(mel_batch, batch_first=True)\n",
        "    return phones_padded, mel_padded\n",
        "\n",
        "train_loader = DataLoader(LJSubset(), batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# --- Train a few steps ---\n",
        "model = FastSpeech2()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "guEOncsoxvlk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mel_pred.shape)  # e.g., torch.Size([batch_size, 131])\n",
        "print(mel_target.shape)  # e.g., torch.Size([batch_size, 833])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_NAKpKoFwjP",
        "outputId": "c4239220-59f7-42a6-ecd7-dfb84647509b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 253, 80])\n",
            "torch.Size([4, 838, 80])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    phones, mels = batch\n",
        "    mel_pred, dur, pitch, energy = model(phones)\n",
        "    mel_pred = mel_pred[:, :mels.size(1), :]  # Align prediction with target length\n",
        "    loss = loss_fn(mel_pred, mels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Loss: {loss.item():.4f}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "SVNmvlZvgz4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1):\n",
        "    for i, (phones, mel_target) in enumerate(train_loader):\n",
        "        mel_pred, _, _, _ = model(phones)\n",
        "        loss = loss_fn(mel_pred, mel_target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 5 == 0:\n",
        "            print(f\"Epoch {epoch}, Step {i}, Loss = {loss.item():.4f}\")\n",
        "        if i == 20:\n",
        "            break\n",
        "\n",
        "# --- Test generation ---\n",
        "model.eval()\n",
        "test_input = torch.tensor([text_to_dummy_phonemes(\"hello world\")], dtype=torch.long)\n",
        "with torch.no_grad():\n",
        "    mel_out, _, _, _ = model(test_input)\n",
        "    print(\"Test mel shape:\", mel_out.shape)\n",
        "    check_mel_specs(mel_out)\n",
        "    wav = mel_to_wav(mel_out[0].transpose(0, 1))\n",
        "\n",
        "# --- Plot waveform ---\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(wav)\n",
        "plt.title(\"Generated Waveform\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "F4meyWmrCThY",
        "outputId": "6e1c236d-99c4-4b37-cf38-05a873bd1eef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([4, 838, 80])) that is different to the input size (torch.Size([4, 253, 80])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (253) must match the size of tensor b (838) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-eed0b31a4324>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mphones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmel_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3884\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (253) must match the size of tensor b (838) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FAXYxmvOsMnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}